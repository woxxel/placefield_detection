{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root_dir = Path.cwd().parents[1]\n",
    "if not root_dir in sys.path:\n",
    "    sys.path.insert(0, str(root_dir))\n",
    "\n",
    "# import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from scipy.signal import find_peaks, peak_widths\n",
    "\n",
    "from placefield_detection.utils import get_spikeNr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_struct_PC_results(nCells, nbin, trial_ct, nStats=5):\n",
    "    results = {}\n",
    "    results[\"status\"] = {}\n",
    "\n",
    "    for key in [\n",
    "        \"MI_value\",\n",
    "        \"MI_p_value\",\n",
    "        \"MI_z_score\",\n",
    "        \"Isec_value\",\n",
    "        \"Isec_p_value\",\n",
    "        \"Isec_z_score\",\n",
    "        \"SNR\",\n",
    "        \"r_value\",\n",
    "    ]:\n",
    "        results[\"status\"][key] = np.full(nCells, np.NaN)\n",
    "\n",
    "    results[\"fields\"] = {\n",
    "        \"parameter\": np.full(\n",
    "            (nCells, 5, 4, nStats), np.NaN\n",
    "        ),  ### (mean,std,CI_low,CI_top)\n",
    "        \"p_x\": np.zeros((nCells, 5, nbin)),  ##sp.sparse.COO((nCells,3,nbin)),#\n",
    "        \"posterior_mass\": np.zeros((nCells, 5)) * np.NaN,\n",
    "        \"reliability\": np.zeros((nCells, 5)) * np.NaN,\n",
    "        \"Bayes_factor\": np.zeros((nCells, 5, 2)) * np.NaN,\n",
    "        \"nModes\": np.zeros(nCells).astype(\"int\"),\n",
    "    }\n",
    "\n",
    "    results[\"firingstats\"] = {\n",
    "        \"rate\": np.full(nCells, np.NaN),\n",
    "        \"map\": np.zeros((nCells, nbin)) * np.NaN,\n",
    "        \"std\": np.zeros((nCells, nbin)) * np.NaN,\n",
    "        \"CI\": np.zeros((nCells, 2, nbin)) * np.NaN,\n",
    "        \"trial_map\": np.zeros((nCells, trial_ct, nbin)) * np.NaN,\n",
    "        \"trial_field\": np.zeros((nCells, 5, trial_ct), \"bool\"),\n",
    "        \"parNoise\": np.zeros((nCells, 2)) * np.NaN,\n",
    "    }\n",
    "\n",
    "    ## if method is called for nCells = 1, collapse data from first dimension\n",
    "    for field in results.keys():\n",
    "        for key in results[field].keys():\n",
    "            results[field][key] = np.squeeze(results[field][key])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PF_thresholding(firing_rate_map, threshold_factor=4, sigma=4):\n",
    "\n",
    "    place_fields = {}\n",
    "    for neuron_idx, neuron_firing_map in enumerate(firing_rate_map):\n",
    "\n",
    "        smooth_map = gaussian_filter1d(neuron_firing_map, sigma=sigma, mode=\"wrap\")\n",
    "        baseline = np.percentile(smooth_map, 50)\n",
    "        _, _, std_rate = get_spikeNr(smooth_map)\n",
    "        threshold = baseline + (threshold_factor * std_rate)\n",
    "\n",
    "        # shifting the peak to center\n",
    "        peak_index = np.argmax(smooth_map)\n",
    "        shift_amount = len(smooth_map) // 2 - peak_index\n",
    "        shifted_map = np.roll(smooth_map, shift_amount)\n",
    "\n",
    "        field_loc, _ = find_peaks(shifted_map, height=threshold, distance=10, width=2)\n",
    "        field_loc = field_loc.tolist()\n",
    "\n",
    "        PF_amplitude = []\n",
    "        place_field_width = []\n",
    "        centroids = []\n",
    "\n",
    "        if field_loc:\n",
    "            PF_amplitude = shifted_map[field_loc].tolist()\n",
    "\n",
    "            widths, _, left_ips, right_ips = peak_widths(\n",
    "                shifted_map, field_loc, rel_height=0.6\n",
    "            )\n",
    "            place_field_width = [int(round(width)) for width in widths]\n",
    "\n",
    "            # calculating centroids for each place field\n",
    "            for i, loc in enumerate(field_loc):\n",
    "\n",
    "                left_idx = int(np.floor(left_ips[i]))\n",
    "                right_idx = int(np.ceil(right_ips[i]))\n",
    "\n",
    "                field_indices = np.arange(left_idx, right_idx + 1)\n",
    "                field_activities = shifted_map[field_indices]\n",
    "\n",
    "                # computing center of mass\n",
    "                centroid = np.sum(field_indices * field_activities) / np.sum(\n",
    "                    field_activities\n",
    "                )\n",
    "                centroid = (centroid - shift_amount) % len(smooth_map)\n",
    "                centroids.append(centroid)\n",
    "\n",
    "        place_fields[neuron_idx] = {\n",
    "            \"baseline\": baseline,\n",
    "            \"amplitude\": PF_amplitude,\n",
    "            \"field_location\": centroids,\n",
    "            \"place_field_width\": place_field_width,\n",
    "            \"nbr_PF\": len(centroids),\n",
    "        }\n",
    "    return place_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_PC_results(results, firing_rate_map, nCells, threshold_factor=4, sigma=4):\n",
    "\n",
    "    # calculating place fields for all neurons\n",
    "    place_fields = PF_thresholding(firing_rate_map, threshold_factor, sigma)\n",
    "\n",
    "    for neuron_ind in range(nCells):\n",
    "        neuron_data = place_fields[neuron_ind]\n",
    "\n",
    "        results[\"fields\"][\"nModes\"][neuron_ind] = neuron_data[\"nbr_PF\"]\n",
    "        for field_ind in range(min(neuron_data[\"nbr_PF\"], 5)):\n",
    "\n",
    "            results[\"fields\"][\"parameter\"][neuron_ind, field_ind, :, 0] = [\n",
    "                neuron_data[\"baseline\"],\n",
    "                neuron_data[\"amplitude\"][field_ind],\n",
    "                neuron_data[\"field_location\"][field_ind],\n",
    "                neuron_data[\"place_field_width\"][field_ind],\n",
    "            ]\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \".../data/AlzheimerMice_Hayashi/579ad/Session10/PC_fields.pkl\"\n",
    "PC_fields = pd.read_pickle(filepath)\n",
    "field_map = PC_fields[\"firingstats\"][\"map\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nCells = len(field_map)\n",
    "nbin = 100\n",
    "trial_ct = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = build_struct_PC_results(nCells, nbin, trial_ct)\n",
    "PC_results = store_PC_results(results, field_map, nCells)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
